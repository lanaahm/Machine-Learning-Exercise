# -*- coding: utf-8 -*-
"""System_Rekomendasi_IMDB_Movies.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E04azSuas82ZBsKghxIqrKh3lclyn8FR

# IMDB Movies Content Based Filtering (KNN and Cosine similarity)

## DataSet Information:
<p align='center'>
	<img  width='100%' src='
https://user-images.githubusercontent.com/57904007/170904420-aa173c83-573b-434b-a316-525faa908e35.png' alt='Sumber: https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows'>
</p>

| Jenis | Keterangan |
| - | - |
| Sumber | [Kaggle Dataset : IMDB Movies Dataset](https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows/metadata) |
| Jenis dan Ukuran Berkas | CSV (438.1 kB) |
| Rating Penggunaan | 10.0 (Silver) |
| Lisensi | CC0: Public Domain |

Penjelasan mengenai variabel-variable pada data diabetes dapat dilihat pada poin-poin berikut:

- `Poster_Link`: Link poster film.
- `Series_Title`: Nama film.
- `Released_Year`: Tahun rilis film.
- `Certificate`: Sertifikat yang diperoleh dari film tersebut.
- `Runtime`: Durasi film.
- `Genre`: Genre film.
- `IMDB_Rating`: Peringkat film pada situs IMDB.
- `Overview`: Sinopsis / ringkasan dari film tersbut.
- `Meta_score`: Skor yang diperoleh dari film tersbut.
- `Director`: Director dari film.
- `Star1,Star2,Star3,Star4`: Pemeran bintang  pada film tersebut.
- `No_of_Votes`: Jumlah total vote dari film tersebut.
- `Gross`: Penghasilan yang diperoleh film tersebut.

## Import Dataset
"""

import os
os.environ['KAGGLE_USERNAME'] = 'lanaahm'
os.environ['KAGGLE_KEY'] = 'c5dac849baf021db5db739062fdf3105'

!kaggle datasets download -d harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows

!unzip /content/imdb-dataset-of-top-1000-movies-and-tv-shows.zip

"""## Import Library"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.impute import KNNImputer
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score
# %matplotlib inline

"""## Data Understanding

### Convert Dataset into pandas
"""

df = pd.read_csv('/content/imdb_top_1000.csv')
df.head()

"""### Dataset Variable Description"""

df.info()

"""### Check Missing Value"""

df.isna().sum()

"""### Check the Description of Dataset Statistics"""

df.describe()

"""## Data Preparation

### Pembersihan data pada setiap kolom

#### Kolom Rating

Pada dataset ini rating terdapat pada 2 kolom yaitu IMDB_Rating dan Meta_score. Berdasarkan informasi IMDB data pada kolom IMDB_Rating adalah sebuah rating dari film berdasarkan rata" dari hasil voting, sedangkan pada kolom Meta_score adalah skor diberikan untuk ulasan film dari sekelompok besar kritikus paling dihormati di dunia.

##### Kolom IMDB_Rating
"""

print('Jumlah data kosong pada kolom IMDB_Rating: ',df.IMDB_Rating.isnull().sum())
print('Jumlah data pada kolom IMDB_Rating: ', len(df.IMDB_Rating))
print('Data unik pada kolom IMDB_Rating:\n', df.IMDB_Rating.unique().tolist())

"""##### Kolom Meta_score"""

print('Jumlah data kosong pada kolom Meta_score: ',df.Meta_score.isnull().sum())
print('Jumlah data pada kolom Meta_score: ', len(df.Meta_score))
print('Data unik pada kolom Meta_score:\n', df.Meta_score.unique())

"""Data Meta_score terdapat nilai yang hilang atau kosong berbeda dengan IMDB_Rating yang memiliki data yang rapih. Pada data ini akan dilakukan pengisian data dengan menggunakan KNNImputer untuk mengatasi data yang hilang dengan cara ini, distribusi data Meta_score akan tetap terjaga pada dikarenakan metode ini akan melakukan pengisian sesuai dengan nilai terdekat."""

# Inisialisasi KNNImputer dengan parameter n_neighbors = 50 untuk melakukan pengisian berdasarkan 50 tetangga terdekat
imputer = KNNImputer(n_neighbors=50)
# Melakukan imputasi pada nilai NaN
df['Meta_score'] = imputer.fit_transform(df[['Meta_score']]).ravel()
# Melakukan pembulatan data pada hasil KNNImputer
df['Meta_score'] = df['Meta_score'].round(decimals=1)


print('Cek jumlah data kosong setelah dilakukan pengisian pada kolom Meta_score: ',df.Meta_score.isnull().sum())

"""#### Kolom Runtime"""

print('Jumlah data kosong pada kolom Runtime: ',df.Runtime.isnull().sum())
print('Jumlah data pada kolom Runtime: ', len(df.Runtime))
print('Data unik pada kolom Runtime:\n', df.Runtime.unique())

"""pada kolom runtime tidak terdapat nilai yang kosong melainkan data tersebut masih dalam bentuk object string sehingga perlu dilakukan konversi data. disini yang dilakukan adalah menghapus nilai min dikarenakan data tersebut dalam bentuk menit."""

# Mengganti nilai pada kolom runtime
df['Runtime']= df['Runtime'].str.replace('min','')
# Mengganti tipe data kolom runtime
df['Runtime'] = df['Runtime'].astype('float')

df['Runtime']

"""#### Kolom Released_Year"""

print('Jumlah data kosong pada kolom Certificate: ',df.Released_Year.isnull().sum())
print('Jumlah data pada kolom Certificate: ', len(df.Released_Year))
print('Data unik pada kolom Certificate:\n', df.Released_Year.unique())

"""dapat dilihat pada data tahun rilis terdapat data dengan tahun rilis PG dan dilakukan analisis lebih lanjut pada dapat tersebut."""

df.loc[df.Released_Year == 'PG']

"""Terdapat 1 data dengan tahun rilis PG pada dapat tersebut dilakukan pengapusan dikarenakan data tersebut hanya 1 sehingga tidak terlalu berpengaruh."""

# Menghapus data Released_Year == PG
df.drop(df.loc[df.Released_Year == 'PG'].index, inplace=True)

# Melakukan konversi data dengan tipe data int
df['Released_Year'] = df['Released_Year'].astype('int')

"""#### Kolom Certificate"""

print('Jumlah data kosong pada kolom Certificate: ',df.Certificate.isnull().sum())
print('Jumlah data pada kolom Certificate: ', len(df.Certificate))
print('Data unik pada kolom Certificate:\n', df.Certificate.unique())

"""Dapat dilihat pada kolom Certificate memiliki data yang kosong dengan jumlah 101 data, dan pada data unik terdapat data unrated yang berarti data terdapat beberapa film yang tidak memiliki Certificate sehingga pada data yang kosong bisa kita isi dengan unrated."""

df['Certificate'].fillna('Unrated', inplace = True)

"""### Pembersihan data duplikasi"""

print('Cek jumlah data duplikat pada dataset: ', df.duplicated().sum())
print('\n\n')
df.info()

"""Dapat dilihat informasi data setelah dilakukan pengisian data pada beberapa komlom yang memiliki data kosong. pada kolom gross data tersebut tidak dilakukan pengisian dikarenakan data tersebut adalah data produksi dari film tersebut sehingga tidak terlalu berpengauh dan dapat dilakukan penghapusan.

### Univariate Analysis
"""

numerical_features = ['Runtime', 'IMDB_Rating', 'Meta_score', 'No_of_Votes']
categorical_features = ['Certificate']

df[categorical_features].value_counts().plot(kind='bar', rot=60)

"""Pada tampilanvisualisasi data diatas dapat dilihat bawah distribusi kategori pada kolom Certificate memiliki distribusi data dengan kategori U berada pada rentang nilai 200, kategori A diretang 150-190, kategori UA berada pada rentang 150-180, dan seterusnya."""

fig = df[numerical_features].hist(bins=50, figsize=(16,8))
[x.ticklabel_format(useOffset=False, style='plain') for x in fig.ravel()]

"""Dapat dilihat pada tampilan visualisasi beberapa kolom data diatas memiliki distribusi data yang bervariasi yang akan dijelaskan sebagai berikut:

- Kolom Runtime, data tersebut merupakan data durasi yang dimiliki setiap film dalam menit dapat dilihat sebaran data runtime film yang memiliki durasi 100 menit berada pada rentang 80, film yang memiliki durasi 150 berapa pada rentang 20-30, dan seterusnya.
- Kolom IMDB_Rating, data tersebut merupakan data rating dari film berdasarkan rata" dari hasil voting pada situs IMDB dapat dilihat sebaran data IMDB_Rating film yang memiliki rating 7.5 menit berada pada rentang 140-160, film yang memiliki rating 8.0 berapa pada rentang 140, dan seterusnya.
- Kolom Meta_Score, data tersebut merupakan data skor yang diberikan untuk ulasan film dari sekelompok besar kritikus paling dihormati di dunia dapat dilihat sebaran data Meta_Score film yang memiliki Meta_Score 60 menit berada pada rentang 20-25, film yang memiliki Meta_Score 70 berapa pada rentang 30-40, dan seterusnya.
- Kolom No_of_votes, data tersebut merupakan data jumlah total vote dari film tersebut dapat dilihat sebaran data No_of_votes pada film yang memiliki vote kurang dari 5 juta vote berada pada rentang 100-360, film yang memiliki vote 5 juta berapa pada rentang 30-5, dan seterusnya.

### Multivariate Analysis
"""

for index, col in enumerate(categorical_features):
  sns.catplot(x=col, y='No_of_Votes', kind='bar', dodge=False, height=3, aspect=6/3, data=df, palette='Set3').set(xlabel=None)
  plt.title("Rata-rata 'No_of_Votes' Relatif terhadap - {}".format(col))
  plt.xticks(rotation=60)
plt.show()

"""Dapat dilihat pada tampilan visualisasi fitur Certificate data diatas memiliki hubungan terhadap hasil jumlah votes film. hasil visualisasi tersebut menunjukan data certificate dengan beberapa kategori yang memiliki hubungan terhadap jumlah. Film yang Certificate A memiliki hubungan dengan hasil jumlah vote yang berada pada kisaran angka 4juta, Film yang Certificate U memiliki hubungan dengan hasil jumlah vote yang berada pada kisaran angka 2juta. dan seterusnya"""

sns.pairplot(df, diag_kind = 'kde')

"""Tampilan visualisasi diatas menunjukkan relasi pasangan dalam dataset. Pada kasus ini hanya fokus terhadap No_of_Votes dari pola sebaran data (titik-titik) pada tampilan di atas, pola data grafik No_of_Votes memiliki korelasi positif. Hal ini ditandai dengan meningkatnya variabel pada sumbu y saat terjadi peningkatan variabel pada sumbu x yang terdapat pada tampilan IMDB_Rating dan Meta_score."""

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix untuk Fitur Numerik', size=20)

"""Dapat dilihat pada tampilan visualisasi korelasi fitur data diatas. Korelasi mengukur kekuatan hubungan antara dua variabel serta arahnya (positif atau negatif). Mengenai kekuatan hubungan antar variabel, semakin dekat nilainya ke 1 atau -1, korelasinya semakin kuat. Sedangkan, semakin dekat nilainya ke 0, korelasinya semakin lemah. Tampilan diatas menunjukan bahwa kolom data Meta_Score memiliki hubungan yang lemah terhadap hasil voteing sehingga dapat dilakukan pengapusan pada kolom data tersebut.

### Penghapusan data yang tidak digunakan
"""

# Menyimpan nama film pada dataframe baru
df_series_title = pd.DataFrame({'Series_Title': df['Series_Title'], 'Genre': df['Genre']})



# Mengubah kolom Series_Title sebagai index
df.set_index('Series_Title',inplace=True)

# Menghapus Kolom yang tidak digunakan
df.drop(['Poster_Link', 'Overview', 'Gross', 'Meta_score'], axis = 1, inplace = True)
df.info()

"""Dapat dilihat kolom menjadi 10 dari 15 kolom gross, Poster_Link, Overview, Meta_score telah dihapus dikarenakan kolom tersebut tidak gunakan. Penghapusan kolom Overview adalah untuk menghindari kemiripan rekomendasi dan rekomendasi menjadi lebih general. pada kolom Meta_score dihapus karenakan memiliki korelasi lemah yang sudah dijelaskan sebelumnya. sedangkan untuk Poster_link dan gross memang tidak digunakan dalam kasus ini.

### Konversi label kategori menjadi one-hot encoding

#### Kolom Genre
"""

# Mengambil setiap unik pada kolom Genre
genres = np.unique(', '.join(df['Genre']).split(', '))
df_one_hot_genre = pd.DataFrame()
# Proses one-hot encoding pada kolom genre
for genre in genres:
    df_one_hot_genre['genre_'+ genre] = df['Genre'].str.contains(genre).astype('int')

# Menghapus kolom Genre pada dataset 
df.drop('Genre', axis = 1, inplace = True)

"""#### Kolom Certificate"""

# Proses one-hot encoding pada kolom Certificate
df_one_hot_certificate = pd.get_dummies(df['Certificate'], prefix='Certificate')

# Menghapus kolom Certificate pada dataset 
df.drop('Certificate', axis = 1, inplace = True)

"""#### Kolom Director"""

# Proses one-hot encoding pada kolom Director
df_one_hot_director = pd.get_dummies(df['Director'], prefix='Director')

# Menghapus kolom Director pada dataset 
df.drop('Director', axis = 1, inplace = True)

"""#### Kolom Star1, Star2, Star3, dan Star4"""

# Proses one-hot encoding pada kolom ['Star1', 'Star2', 'Star3', 'Star4']
column_stars = df[['Star1', 'Star2', 'Star3', 'Star4']].keys()
df_one_hot_stars = pd.get_dummies(df[column_stars])

# Menghapus kolom ['Star1', 'Star2', 'Star3', 'Star4'] pada dataset 
df.drop(['Star1', 'Star2', 'Star3', 'Star4'], axis = 1, inplace = True)

"""### Mengabungkan proses one hot encoding dengan dataset"""

# Mengabungkan proses one hot encoding dengan dataset
df = pd.concat([df, df_one_hot_certificate, df_one_hot_genre, df_one_hot_director, df_one_hot_stars],axis=1)
df.head()

"""### Normalisasi data Numerik"""

scaler = MinMaxScaler()

column_numeric = ['Released_Year', 'Runtime', 'IMDB_Rating', 'No_of_Votes']
scaler.fit(df[column_numeric])
df[column_numeric] = scaler.transform(df.loc[:, column_numeric])

df[column_numeric].describe().round(4)

"""## Model Development Content Based Filtering

#### K-Nearest Neighbor
"""

# Membuat sistem rekomendasi dengan model K-Nearest Neighbor
# Inisiasi model 
model = NearestNeighbors(metric='euclidean')

# Melakukan fitting model terhadap data
model.fit(df)

# Recommender KNN
def getRecommenderMovies_KNN(movies:str, recommend_movies:int=10):
  print(f'Apabila pengguna menyukai film {movies}\n{recommend_movies} film berikut dapat direkomendasikan pada pengguna :')

  # Mencari film terdekat dengan film yang disukai
  distances, neighbors = model.kneighbors(df.loc[df.index == movies], n_neighbors=recommend_movies)

  # Memasukkan film yang sama pada list similar_movies
  similar_movies, genre = [], []
  for movei_title in df_series_title.loc[neighbors[0][:]].values:
    similar_movies.append(movei_title[0])
    genre.append(movei_title[1])

  # Memasukan nilai kemiripan pada sebuah list
  similar_distance = []
  for distance in distances[0]:
    similar_distance.append(f"{round(100-distance, 2)}%")
    
  # Menampilkan remokendasi pada pengguna
  return pd.DataFrame(data = {"Nama Film" : similar_movies, "Genre" : genre, "Tingkat Kesamaan" : similar_distance})

getRecommenderMovies_KNN(df_series_title.loc[10][0])

"""### Cosine Similarity"""

# Menghitung cosine similarity dari dataframe
cosine_sim = cosine_similarity(df)

# Menyimpan hasil perhitungan pada dataframe
cosine_sim_df = pd.DataFrame(cosine_sim, index=df_series_title['Series_Title'], columns=df_series_title['Series_Title'])
# cosine_sim_df.head()

# Recommender Cosine Similarity
def getRecommenderMovies_cosine(movies:str, recommend_movies:int=10):
  print(f'Apabila pengguna menyukai film {movies[0]}\n{recommend_movies} film berikut dapat direkomendasikan pada pengguna :')

  # Mencari nilai unik pada aplikasi yang disukai pengguna di baris dataframe cosine sim
  # Nilai unik (arr) dikembalikan dalam bentuk yang berurutan dari kecil ke besar 
  arr, ind = np.unique(cosine_sim_df.loc[movies[0]], return_index=True)

  # Memasukkan film yang sama pada list similar_movies
  similar_movies, genre = [], []
  for index in ind[-(recommend_movies+1):-1]:
    similar_movies.append(df_series_title.loc[index][0])
    genre.append(df_series_title.loc[index][1])

  # Memasukkan skor cosine dari aplikasi yang serupa mulai dari index kedua terakhir sampai index n terakhir
  cosine_score = []
  for score in arr[-(recommend_movies+1):-1]:
    cosine_score.append(score)
  
  # Menampilkan remokendasi pada pengguna
  return pd.DataFrame(data = {"Nama Film" : similar_movies, "Genre" : genre, 'Tingkat Kesamaan' : cosine_score}).sort_values(by='Tingkat Kesamaan',ascending=False)

getRecommenderMovies_cosine(df_series_title.loc[10])

"""## Evaluasi

### Precission

Presisi adalah kemampuan pengklasifikasi untuk tidak melabeli instance positif yang sebenarnya negatif. Untuk setiap kelas itu didefinisikan sebagai rasio positif benar dengan jumlah positif benar dan salah. berikut merupakan formula dari precission.
  ```
  TP – True Positives
  FP – False Positives

  Precision = TP/(TP + FP)
  ```

#### KNN
Precision pada hasil pendekatan KNN didapatkan nilai 90%. dikarenakan hasil prediksi yang memiliki genre serupa berjumlah 9 dan 1 rekomendasi memiliki genre Fantasy

#### Cosine Similarity
Precision pada hasil pendekatan Cosine Similarity didapatkan nilai 70%. dikarenakan hasil prediksi yang memiliki genre serupa berjumlah 7 dan 3 rekomendasi memiliki genre Fantasy dan Animation

### Davies Bouldin
"""

davies_bouldin_score(df, df_series_title['Series_Title'])

"""Davies Bouldin adalah skema evaluasi internal, di mana validasi seberapa baik pengelompokan telah dilakukan dilakukan dengan menggunakan jumlah dan fitur yang melekat pada dataset. Davies-Bouldin mengukur rasio antara jarak dalam cluster dan antara jarak cluster dan menghitung rata-rata keseluruhan cluster. Oleh karena itu relatif sederhana, dibatasi – 0 hingga 1, skor yang lebih rendah lebih baik.

### Calinski Harabasz
"""

calinski_harabasz_score(df, df_series_title['Series_Title'])

"""Calinski-Harabasz membandingkan varians antar-cluster dengan varians dalam setiap cluster. Semakin tinggi skor semakin baik pemisahannya."""

